{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "b1b91GLtMmhn",
        "OkOl4q7TGiWR",
        "oeOIi2SgMji8",
        "H94v54UPW2U4",
        "bxz1Vnn1eS6s",
        "AYch3TXde559"
      ],
      "authorship_tag": "ABX9TyNNfPCuNa/BkA9q2fMs8QFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sid200026/Misc-Programs/blob/master/CUDA/Introduction_to_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1b91GLtMmhn"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1pcdfLGFwZC"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNfikEN7GB3s"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeMWNAM0GIlD"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jevl7-jFGJIw"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtw1je5fGLdl",
        "outputId": "8cc6253b-d282-427a-b201-86a9dca34488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkOl4q7TGiWR"
      },
      "source": [
        "# Hello World"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXc6M91GJ1EG"
      },
      "source": [
        "# The __global__ specifier indicates a function that runs on device (GPU)\n",
        "# Such function can be called through host code\n",
        "\n",
        "# CPU -> host\n",
        "# GPU -> device"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLriOYCPGjmX",
        "outputId": "0bb83937-6ee0-4e80-dabb-389d1098967a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "__global__ void cuda_hello() {\n",
        "    printf(\"Hello world from CUDA\"); // Printing doesn't produce an output to the kernel\n",
        "}\n",
        "\n",
        "main() {\n",
        "    cuda_hello<<<1,1>>>();\n",
        "}"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeOIi2SgMji8"
      },
      "source": [
        "# Vector Addition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WejsomoPwgW"
      },
      "source": [
        "\"\"\"\n",
        "CPU and GPUs are separate entities.  Both have their own memory space. \n",
        "CPU cannot directly access GPU memory, and vice versa. \n",
        "In CUDA terminology, CPU memory is called host memory and GPU memory is called device memory. \n",
        "Pointers to CPU and GPU memory are called host pointer and device pointer, respectively.\n",
        "\n",
        "For data to be accessible by GPU, it must be presented in the device memory. \n",
        "CUDA provides APIs for allocating device memory and data transfer between host and device memory. \n",
        "Following is the common workflow of CUDA programs.\n",
        "\n",
        "Allocate host memory and initialized host data\n",
        "Allocate device memory\n",
        "Transfer input data from host to device memory\n",
        "Execute kernels\n",
        "Transfer output from device memory to host\n",
        "\n",
        "cudaMalloc(void **devPtr, size_t count);\n",
        "cudaFree(void *devPtr);\n",
        "cudaMemcpy(void *dst, void *src, size_t count, cudaMemcpyKind kind)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "261qqPZlMu95",
        "outputId": "e74c477c-a4be-4542-c286-0eec612672ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 10\n",
        "\n",
        "__global__ void cuda_add(float* c, float* b, float* a) {\n",
        "    for(int i=0; i<N; i++) {\n",
        "        c[i] = *(a+i) + *(b+i);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *a, *b, *c;\n",
        "    // Host Memory\n",
        "    a = (float*)malloc(sizeof(float)*N);\n",
        "    b = (float*)malloc(sizeof(float)*N);\n",
        "    c = (float*)malloc(sizeof(float)*N);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        a[i] = 1.2f*i;\n",
        "        b[i] = 2.3f*i/2;\n",
        "    }\n",
        "    // Device Memory\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void**)&d_a, sizeof(float)*N);\n",
        "    cudaMalloc((void**)&d_b, sizeof(float)*N);\n",
        "    cudaMalloc((void**)&d_c, sizeof(float)*N);\n",
        "    // Host -> Device\n",
        "    cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "    cuda_add<<<1,1>>>(d_c, d_a, d_b);\n",
        "    cudaMemcpy(c, d_c, sizeof(float) * N, cudaMemcpyDeviceToHost);\n",
        "    for(int i=0; i<5; i++) {\n",
        "        printf(\"%f\\n\", c[i]);\n",
        "    }\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    \n",
        "}"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.000000\n",
            "2.350000\n",
            "4.700000\n",
            "7.050000\n",
            "9.400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H94v54UPW2U4"
      },
      "source": [
        "# Parallelism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrdCtqBPW4u_"
      },
      "source": [
        "\"\"\"\n",
        "The above two programs uses 1 GPU thread ( <<<1,1>>> )\n",
        "\n",
        "CUDA organizes threads into a group called \"thread block\".\n",
        "Kernel can launch multiple thread blocks, organized into a \"grid\" structure.\n",
        "\n",
        "<<< M , T >>>\n",
        "Which indicate that a kernel launches with a grid of M thread blocks. \n",
        "Each thread block has T parallel threads.\n",
        "\n",
        "blockIdx.x contains the index of the block with in the grid\n",
        "gridDim.x contains the size of the grid\n",
        "threadIdx.x contains the index of the thread within the block\n",
        "blockDim.x contains the size of thread block (number of threads in the thread block).\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcwHshgaYpLy"
      },
      "source": [
        "### Vector Addition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bho2NUdwYocf",
        "outputId": "b24fc20d-3202-4271-9570-42ad0f96d568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 10\n",
        "\n",
        "__global__ void cuda_add(float* c, float* b, float* a) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(tid < N)\n",
        "      c[tid] = *(a+tid) + *(b+tid);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *a, *b, *c;\n",
        "    // Host Memory\n",
        "    a = (float*)malloc(sizeof(float)*N);\n",
        "    b = (float*)malloc(sizeof(float)*N);\n",
        "    c = (float*)malloc(sizeof(float)*N);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        a[i] = 1.2f*i;\n",
        "        b[i] = 2.3f*i/2;\n",
        "    }\n",
        "    // Device Memory\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void**)&d_a, sizeof(float)*N);\n",
        "    cudaMalloc((void**)&d_b, sizeof(float)*N);\n",
        "    cudaMalloc((void**)&d_c, sizeof(float)*N);\n",
        "    // Host -> Device\n",
        "    cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "    int block_size = 256;\n",
        "    int grid_size = ((N + block_size) / block_size);\n",
        "    cuda_add<<<grid_size,block_size>>>(d_c, d_a, d_b);\n",
        "    cudaMemcpy(c, d_c, sizeof(float) * N, cudaMemcpyDeviceToHost);\n",
        "    for(int i=0; i<5; i++) {\n",
        "        printf(\"%f\\n\", c[i]);\n",
        "    }\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c); \n",
        "}"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.000000\n",
            "2.350000\n",
            "4.700000\n",
            "7.050000\n",
            "9.400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAI7a-U1bFTk"
      },
      "source": [
        "# Practice Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxz1Vnn1eS6s"
      },
      "source": [
        "### Multiply Vector By a constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drptx0cXbdpg",
        "outputId": "5b49d2f5-1772-4399-8911-b8c658abe89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 15\n",
        "#define constant 8\n",
        "\n",
        "__global__ void cuda_multiply(int *vector) {\n",
        "    int thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(thread_id < N) {\n",
        "      vector[thread_id] = vector[thread_id]*constant;        \n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void cuda_random_assign(int *vector) {\n",
        "    int thread_num = threadIdx.x;\n",
        "    int thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(thread_id < N) {\n",
        "      vector[thread_id] = thread_num;        \n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    \n",
        "    int block_size = 4;\n",
        "    int grid_size = (block_size+N)/block_size;\n",
        "\n",
        "    int *vector;\n",
        "    vector = (int*)malloc(sizeof(int) * N);\n",
        "\n",
        "    int *d_vector_assign;\n",
        "    cudaMalloc((void**)&d_vector_assign, sizeof(int)*N);\n",
        "    cudaMemcpy(d_vector_assign, vector, sizeof(int) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cuda_random_assign<<<grid_size, block_size>>>(d_vector_assign);\n",
        "    cudaMemcpy(vector, d_vector_assign, sizeof(int) * N, cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_vector_assign);\n",
        "\n",
        "    int *d_vector;\n",
        "    cudaMalloc((void**)&d_vector, sizeof(int)*N);\n",
        "    cudaMemcpy(d_vector, vector, sizeof(int) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cuda_multiply<<<grid_size, block_size>>>(d_vector);\n",
        "    cudaMemcpy(vector, d_vector, sizeof(int) * N, cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_vector);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        printf(\"%d \", vector[i]);\n",
        "    }\n",
        "    free(vector);\n",
        "}"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 8 16 24 0 8 16 24 0 8 16 24 0 8 16 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYch3TXde559"
      },
      "source": [
        "### Square of values of a matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETfaLONPe90U",
        "outputId": "7d5446ce-5cb1-40ef-b39b-1cdc77aff8f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 6\n",
        "\n",
        "// Flattens the 2D Array into a 1D following Row-Major\n",
        "\n",
        "__global__ void cuda_square(int *matrix) {\n",
        "    int row=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    if(row < N*N) {\n",
        "      matrix[row] = matrix[row] * matrix[row] ;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int block_size = N;\n",
        "    int grid_size = N;\n",
        "    int *matrix;\n",
        "    matrix = (int*)malloc(sizeof(int)*N*N);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        for(int j=0; j<N; j++) {\n",
        "            int num = j*i+j;\n",
        "            matrix[i*N+j] = num;\n",
        "        }\n",
        "    }\n",
        "    int *d_matrix;\n",
        "    cudaMalloc((void**)&d_matrix, sizeof(int)*N*N);\n",
        "    cudaMemcpy(d_matrix, matrix, sizeof(int) * N * N, cudaMemcpyHostToDevice);\n",
        "    cuda_square<<<grid_size, block_size>>>(d_matrix);\n",
        "    cudaMemcpy(matrix, d_matrix, sizeof(int) * N * N, cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_matrix);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        for(int j=0; j<N; j++) {\n",
        "          printf(\"%d \", matrix[i*N + j]);   \n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }    \n",
        "    free(matrix);\n",
        "}"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 4 9 16 25 \n",
            "0 4 16 36 64 100 \n",
            "0 9 36 81 144 225 \n",
            "0 16 64 144 256 400 \n",
            "0 25 100 225 400 625 \n",
            "0 36 144 324 576 900 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLTqGynow_FU"
      },
      "source": [
        "### Multiples of all elements in an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoN7ZMWuxjQY",
        "outputId": "c4efe2a3-f865-4d07-8e99-d23d3e0fe883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 6\n",
        "#define M 3\n",
        "\n",
        "__global__ void cuda_square(int *vector, int *matrix) {\n",
        "    int row=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    for(int i=0; i<M; i++) {\n",
        "        matrix[row*M+i] = vector[row] * (i+1);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int block_size = N/2;\n",
        "    int grid_size = (block_size+N)/block_size;\n",
        "    int *vector, *matrix;\n",
        "    vector = (int*)malloc(sizeof(int)*N);\n",
        "    matrix = (int*)malloc(sizeof(int)*N*M);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        vector[i] = i+1;\n",
        "    }\n",
        "    int *d_vector, *d_matrix;\n",
        "    cudaMalloc((void**)&d_vector, sizeof(int)*N);\n",
        "    cudaMemcpy(d_vector, vector, sizeof(int) * N, cudaMemcpyHostToDevice);\n",
        "    cudaMalloc((void**)&d_matrix, sizeof(int)*N*M);\n",
        "    cuda_square<<<grid_size, block_size>>>(d_vector, d_matrix);\n",
        "    cudaMemcpy(matrix, d_matrix, sizeof(int) * N * M, cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_matrix);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        for(int j=0; j<M; j++) {\n",
        "          printf(\"%d \", matrix[i*M + j]);   \n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }    \n",
        "    free(matrix);\n",
        "}"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 2 3 \n",
            "2 4 6 \n",
            "3 6 9 \n",
            "4 8 12 \n",
            "5 10 15 \n",
            "6 12 18 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmkTud7M3QuH"
      },
      "source": [
        "### Rank of a matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dS4yrHBHYW2",
        "outputId": "c99b7a29-65cc-4fd4-c226-2387b2c528c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 4\n",
        "// N rows, N columns\n",
        "\n",
        "__global__ void cuda_transpose(int *matrix, int *rank) {\n",
        "    bool *flag = (bool*)malloc(sizeof(bool) * N);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        flag[i] = false;\n",
        "    }\n",
        "    for(int j=0; j<N; j++) {\n",
        "        if(flag[j])\n",
        "            continue;\n",
        "        for(int i=j+1; i<N; i++) {\n",
        "            if(flag[i])\n",
        "                continue;\n",
        "            int div = -1;\n",
        "            for(int k=0; k<N; k++) {\n",
        "              int div_2 = matrix[i+k*N] / matrix[j+k*N];\n",
        "              if(matrix[i+k*N] % matrix[j+k*N] != 0) {\n",
        "                  div = -1;\n",
        "                  break;\n",
        "              }\n",
        "              if(div == -1)\n",
        "                  div = div_2;\n",
        "              if(div != div_2) {\n",
        "                  div = -1;\n",
        "                  break;\n",
        "              }\n",
        "            }\n",
        "            if(div != -1) {\n",
        "                flag[i] = true;\n",
        "                rank[0] -= 1;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int block_size = 1;\n",
        "    int grid_size = 1;\n",
        "    int *matrix = (int*)malloc(sizeof(int) * N * N);\n",
        "    int *rank = (int*)malloc(sizeof(int));\n",
        "    rank[0] = N;\n",
        "    for(int i=0; i<N*N; i++) {\n",
        "        matrix[i] = i+2;\n",
        "    }\n",
        "    for(int i=0; i<N; i++) {\n",
        "        for(int j=0; j<N; j++) {\n",
        "            printf(\"%d \", matrix[i*N+j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    int *d_matrix, *d_rank;\n",
        "    cudaMalloc((void**)&d_matrix, sizeof(int)*N*N);\n",
        "    cudaMemcpy(d_matrix, matrix, sizeof(int) * N*N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaMalloc((void**)&d_rank, sizeof(int));\n",
        "    cudaMemcpy(d_rank, new int(N), sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cuda_transpose<<<grid_size, block_size>>>(d_matrix, d_rank);\n",
        "    cudaMemcpy(rank, d_rank, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf(\"%d\", *(rank));\n",
        "}"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 3 4 5 \n",
            "6 7 8 9 \n",
            "10 11 12 13 \n",
            "14 15 16 17 \n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrI4pHxf5tvk"
      },
      "source": [
        "### Transpose of a matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo-irdAV556k",
        "outputId": "ac9395d3-a880-40d7-e9f9-41f7cbd5a6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 4\n",
        "#define M 4\n",
        "// N rows, M columns\n",
        "\n",
        "__global__ void cuda_transpose(int *matrix, int *transpose) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = tid / N;\n",
        "    int col = tid-row*N;\n",
        "    if(row*N + col < (N*M)) {\n",
        "        transpose[col*M + row] = matrix[row*N + col];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int block_size = N/2;\n",
        "    int grid_size = (block_size+N*M)/block_size;\n",
        "    int *matrix = (int*)malloc(sizeof(int) * M * N);\n",
        "    for(int i=0; i<N*M; i++) {\n",
        "        matrix[i] = i+1;\n",
        "    }\n",
        "    int *d_matrix, *d_transpose;\n",
        "    cudaMalloc((void**)&d_matrix, sizeof(int)*N*M);\n",
        "    cudaMemcpy(d_matrix, matrix, sizeof(int) * N*M, cudaMemcpyHostToDevice);\n",
        "    cudaMalloc((void**)&d_transpose, sizeof(int)*N*M);\n",
        "    cuda_transpose<<<grid_size, block_size>>>(d_matrix, d_transpose);\n",
        "    cudaMemcpy(matrix, d_transpose, sizeof(int) * N * M, cudaMemcpyDeviceToHost);\n",
        "    for(int i=0; i<M; i++) {\n",
        "        for(int j=0; j<N; j++) {\n",
        "            printf(\"%d \", matrix[i*M+j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 5 9 13 \n",
            "2 6 10 14 \n",
            "3 7 11 15 \n",
            "4 8 12 16 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSlFN9XX_-TW"
      },
      "source": [
        "### Reverse an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6teG178RAAcI",
        "outputId": "a1a8b606-440f-470e-e1fd-be4ee3e7462b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 10\n",
        "\n",
        "__global__ void cuda_reverse(int* vector) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(tid<=N/2) {\n",
        "        int other_index = N-tid-1;\n",
        "        int temp = vector[other_index];\n",
        "        vector[other_index] = vector[tid];\n",
        "        vector[tid] = temp;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int block_size = N/2;\n",
        "    int grid_size = (block_size+N)/block_size;\n",
        "    int *vector = (int*)malloc(sizeof(int) * N);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        vector[i] = i+1;\n",
        "    }\n",
        "    int *d_vector;\n",
        "    cudaMalloc((void**)&d_vector, sizeof(int)*N);\n",
        "    cudaMemcpy(d_vector, vector, sizeof(int)*N, cudaMemcpyHostToDevice);\n",
        "    cuda_reverse<<<grid_size, block_size>>>(d_vector);\n",
        "    cudaMemcpy(vector, d_vector, sizeof(int)*N, cudaMemcpyDeviceToHost);\n",
        "    for(int j=0; j<N; j++) {\n",
        "        printf(\"%d \", vector[j]);\n",
        "    }\n",
        "}"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 9 8 7 6 5 4 3 2 1 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jT8-yQ1BXuP"
      },
      "source": [
        "### Multiply 3 vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDRUA-N0Bbv0",
        "outputId": "19aa57f6-24e0-4379-ed91-bf7e7e2eaab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 15\n",
        "\n",
        "__global__ void cuda_multiply(int *vector1, int *vector2, int *vector3) {\n",
        "    int thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(thread_id < N) {\n",
        "      vector1[thread_id] *= vector2[thread_id]*vector3[thread_id];        \n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    \n",
        "    int grid_size = 3;\n",
        "    int block_size = (N/grid_size)+1;\n",
        "\n",
        "    int *vector1, *vector2, *vector3;\n",
        "    vector1 = (int*)malloc(sizeof(int) * N);\n",
        "    vector2 = (int*)malloc(sizeof(int) * N);\n",
        "    vector3 = (int*)malloc(sizeof(int) * N);\n",
        "\n",
        "    // Random value generator\n",
        "    for(int i=0; i<N; i++) {\n",
        "        vector1[i] = 4*(i+1);\n",
        "        vector2[i] = vector1[i] +1;\n",
        "        vector3[i] = 2*i;\n",
        "    }\n",
        "\n",
        "    int *d_vector1, *d_vector2, *d_vector3;\n",
        "\n",
        "    cudaMalloc((void**)&d_vector1, sizeof(int)*N);\n",
        "    cudaMemcpy(d_vector1, vector1, sizeof(int) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaMalloc((void**)&d_vector2, sizeof(int)*N);\n",
        "    cudaMemcpy(d_vector2, vector2, sizeof(int) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaMalloc((void**)&d_vector3, sizeof(int)*N);\n",
        "    cudaMemcpy(d_vector3, vector3, sizeof(int) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cuda_multiply<<<grid_size, block_size>>>(d_vector1, d_vector2, d_vector3);\n",
        "    cudaMemcpy(vector1, d_vector1, sizeof(int) * N, cudaMemcpyDeviceToHost);\n",
        "    for(int i=0; i<N; i++) {\n",
        "        printf(\"%d \", vector1[i]);\n",
        "    }\n",
        "    free(vector1);\n",
        "    free(vector2);\n",
        "    free(vector3);\n",
        "}"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 144 624 1632 3360 6000 9744 14784 21312 29520 39600 51744 66144 82992 102480 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}